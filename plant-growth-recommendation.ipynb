{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1760012,"sourceType":"datasetVersion","datasetId":1046158}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#data-set\n\nimport pandas as pd\n\n# Sample data\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\nprint(df)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-18T18:09:34.957120Z","iopub.execute_input":"2023-11-18T18:09:34.958082Z","iopub.status.idle":"2023-11-18T18:09:34.971601Z","shell.execute_reply.started":"2023-11-18T18:09:34.958049Z","shell.execute_reply":"2023-11-18T18:09:34.970279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T16:30:05.406679Z","iopub.execute_input":"2023-11-18T16:30:05.407050Z","iopub.status.idle":"2023-11-18T16:30:05.485971Z","shell.execute_reply.started":"2023-11-18T16:30:05.407015Z","shell.execute_reply":"2023-11-18T16:30:05.484573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data preprocessing and Model training\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load your dataset\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\ndf = pd.DataFrame(data)\n# Sum the values in columns 'N', 'P', and 'K' for each row\ndf['Sum'] = df[['N', 'P', 'K']].sum(axis=1)\n\n# Define recommended actions based on rules (example rules)\ndef get_recommended_action(row):\n    if row['N'] < 3:\n        return 'Add Fertilizer'\n    if row['P'] < 3:\n        return 'Add Phosphorus'\n    if row['rainfall'] < 150:  \n        return 'Increase Watering'\n    if row['humidity'] < 60:  \n        return 'Provide More Humidity'\n    if row['N'] > 4 and row['P'] > 4 and row['K'] > 4:\n        return 'Optimal Nutrient Levels'\n    return 'No Specific Action'  \n    \n\n# Apply the rules to generate recommended actions\ndf['Recommended_Action'] = df.apply(get_recommended_action, axis=1)\n\n# Handling Missing Values: Drop rows with missing values\ndata.dropna(inplace=True)\nprint(df.columns)\n\n# Encoding Categorical Variables (if any):\nlabel_encoder = LabelEncoder()\ndf['Recommended_Action_Encoded'] = label_encoder.fit_transform(df['Recommended_Action'])\n\n# Define features (X) and target (y)\nX = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\ny = df['Recommended_Action_Encoded']\n\n# Feature Scaling (if necessary):\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# Model Training: Train a Random Forest Classifier model\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:06:53.953632Z","iopub.execute_input":"2023-11-19T07:06:53.954137Z","iopub.status.idle":"2023-11-19T07:06:54.275628Z","shell.execute_reply.started":"2023-11-19T07:06:53.954102Z","shell.execute_reply":"2023-11-19T07:06:54.273840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Nitrogen-plot\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a histogram for the 'N' feature\nplt.figure(figsize=(8, 6))\nsns.histplot(df['N'], bins=20, kde=True)\nplt.title('Distribution of N')\nplt.xlabel('N')\nplt.ylabel('Frequency')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T16:30:13.616588Z","iopub.execute_input":"2023-11-18T16:30:13.616959Z","iopub.status.idle":"2023-11-18T16:30:14.337221Z","shell.execute_reply.started":"2023-11-18T16:30:13.616930Z","shell.execute_reply":"2023-11-18T16:30:14.336363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#phosporous plot\n\nimport matplotlib.pyplot as plt\n\n# Create a box plot for a single feature\nplt.figure(figsize=(8, 6))\nplt.boxplot(df['P'])\nplt.title('Box Plot of P')\nplt.ylabel('P')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T16:30:18.351090Z","iopub.execute_input":"2023-11-18T16:30:18.351521Z","iopub.status.idle":"2023-11-18T16:30:18.534424Z","shell.execute_reply.started":"2023-11-18T16:30:18.351490Z","shell.execute_reply":"2023-11-18T16:30:18.533330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a histogram for the 'P' feature\nplt.figure(figsize=(8, 6))\nsns.histplot(df['P'], bins=20, kde=True)\nplt.title('Distribution of P')\nplt.xlabel('P')\nplt.ylabel('Frequency')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T16:30:21.816748Z","iopub.execute_input":"2023-11-18T16:30:21.817158Z","iopub.status.idle":"2023-11-18T16:30:22.174236Z","shell.execute_reply.started":"2023-11-18T16:30:21.817124Z","shell.execute_reply":"2023-11-18T16:30:22.173532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pair-plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a pair plot for selected features\nsns.set(style=\"ticks\")\nsns.pairplot(df[['N', 'P', 'K', 'temperature', 'humidity']], kind='scatter')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:07:18.977299Z","iopub.execute_input":"2023-11-18T17:07:18.977653Z","iopub.status.idle":"2023-11-18T17:07:24.581654Z","shell.execute_reply.started":"2023-11-18T17:07:18.977628Z","shell.execute_reply":"2023-11-18T17:07:24.580353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Join plot\nsns.jointplot(x=\"rainfall\",y=\"humidity\",data=df[(df['temperature']<40) & \n                                                  (df['rainfall']>40)],height=10,hue=\"label\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T17:57:48.287804Z","iopub.execute_input":"2023-11-18T17:57:48.288185Z","iopub.status.idle":"2023-11-18T17:57:49.770828Z","shell.execute_reply.started":"2023-11-18T17:57:48.288159Z","shell.execute_reply":"2023-11-18T17:57:49.769591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a histogram for the 'K' feature\nplt.figure(figsize=(8, 6))\nsns.histplot(df['K'], bins=20, kde=True)\nplt.title('Distribution of K')\nplt.xlabel('K')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T16:30:38.964066Z","iopub.execute_input":"2023-11-18T16:30:38.964980Z","iopub.status.idle":"2023-11-18T16:30:39.284633Z","shell.execute_reply.started":"2023-11-18T16:30:38.964937Z","shell.execute_reply":"2023-11-18T16:30:39.283508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation matrix\nimport numpy as np\nimport pandas as pd \nnumeric_df = df.select_dtypes(include=[np.number])\nfig, ax = plt.subplots(1, 1, figsize=(15, 9))\n\nsns.heatmap(numeric_df.corr(), annot=True,cmap='viridis')\nax.set(xlabel='features')\nax.set(ylabel='features')\n\nplt.title('Correlation between different features', fontsize = 15, c='black')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T16:30:43.650497Z","iopub.execute_input":"2023-11-18T16:30:43.651109Z","iopub.status.idle":"2023-11-18T16:30:44.178987Z","shell.execute_reply.started":"2023-11-18T16:30:43.651078Z","shell.execute_reply":"2023-11-18T16:30:44.178058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accuracy by kNN algorithm\n\nimport numpy as np\nimport pandas as pd\n\n# Load your dataset\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\ndf = pd.DataFrame(data)\n# Define recommended actions based on rules (example rules)\ndef get_recommended_action(row):\n    if row['N'] < 3:\n        return 'Add Fertilizer'\n    if row['P'] < 3:\n        return 'Add Phosphorus'\n    if row['rainfall'] < 45:  \n        return 'Increase Watering'\n    if row['humidity'] < 60:  \n        return 'Provide More Humidity'\n    if row['N'] > 4 and row['P'] > 4 and row['K'] > 4:\n        return 'Optimal Nutrient Levels'\n    return 'No Specific Action'  \ndf['Recommended_Action'] = df.apply(get_recommended_action, axis=1)\nfeatures = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]\ntarget = df['Recommended_Action']\n\nacc = []\nmodel = []\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(features,target,test_size = 0.2,random_state =2)\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\n\nknn = KNeighborsClassifier()\n\nknn.fit(x_test,y_test)\n\npredicted_values = knn.predict(x_test)\n\nx = metrics.accuracy_score(y_test, predicted_values)\nacc.append(x)\nmodel.append('K Nearest Neighbours')\nprint(\"KNN Accuracy is: \", x)\n\nprint(classification_report(y_test,predicted_values))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:56:50.091967Z","iopub.execute_input":"2023-10-19T11:56:50.093355Z","iopub.status.idle":"2023-10-19T11:56:50.206533Z","shell.execute_reply.started":"2023-10-19T11:56:50.093312Z","shell.execute_reply":"2023-10-19T11:56:50.204910Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load your dataset\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\ndf = pd.DataFrame(data)\n# Sum the values in columns 'N', 'P', and 'K' for each row\ndf['Sum'] = df[['N', 'P', 'K']].sum(axis=1)\n\n# Define recommended actions based on rules (example rules)\ndef get_recommend_action(row):\n    optimal_ratio = {'N': 4, 'P': 2, 'K': 1}\n    \n    # Calculate the ratio for the current nutrient levels\n    current_ratio = {\n        'N': row['N'] / optimal_ratio['N'],\n        'P': row['P'] / optimal_ratio['P'],\n        'K': row['K'] / optimal_ratio['K']\n    }\n\n    # Check if any nutrient exceeds or falls below the optimal ratio\n    exceeding_nutrients = [nutrient for nutrient in current_ratio if current_ratio[nutrient] > 1]\n    below_optimal_nutrients = [nutrient for nutrient in current_ratio if current_ratio[nutrient] < 1]\n\n    # Define recommended actions based on nutrient levels\n    if exceeding_nutrients:\n        return f\"Add {', '.join(exceeding_nutrients)} Fertilizer\"\n    elif below_optimal_nutrients:\n        return f\"Increase {', '.join(below_optimal_nutrients)} Fertilizer\"\n    else:\n        return 'Optimal Nutrient Levels'\n\n\n# Apply the rules to generate recommended actions\ndf['Recommended_Action'] = df.apply(get_recommended_action, axis=1)\n\n# Handling Missing Values: Drop rows with missing values\ndata.dropna(inplace=True)\nprint(df.columns)\n\n# Encoding Categorical Variables (if any):\nlabel_encoder = LabelEncoder()\ndf['Recommended_Action_Encoded'] = label_encoder.fit_transform(df['Recommended_Action'])\n\n# Define features (X) and target (y)\nX = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\ny = df['Recommended_Action_Encoded']\n\n# Feature Scaling (if necessary):\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# Model Training: Train a Random Forest Classifier model\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T16:30:48.105175Z","iopub.execute_input":"2023-11-18T16:30:48.106087Z","iopub.status.idle":"2023-11-18T16:30:48.457126Z","shell.execute_reply.started":"2023-11-18T16:30:48.106051Z","shell.execute_reply":"2023-11-18T16:30:48.455725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Define recommended actions based on rules (example rules)\ndef recommend_nutrient_action_individual(row):\n    optimal_ratio = {'N': 4, 'P': 2, 'K': 1}\n    \n    # Calculate the ratio for each nutrient individually\n    ratios = {nutrient: row[nutrient] / (row['N'] + row['P'] + row['K']) for nutrient in optimal_ratio.keys()}\n\n    # Initialize lists to store nutrient names\n    exceeding_nutrients = []\n    below_optimal_nutrients = []\n    optimal_nutrients = []\n\n    # Check if any nutrient exceeds, falls below, or is within the optimal ratio\n    for nutrient, ratio in ratios.items():\n        if ratio > optimal_ratio[nutrient] / sum(optimal_ratio.values()):\n            exceeding_nutrients.append(nutrient)\n        elif ratio < optimal_ratio[nutrient] / sum(optimal_ratio.values()):\n            below_optimal_nutrients.append(nutrient)\n        else:\n            optimal_nutrients.append(nutrient)\n\n    return exceeding_nutrients, below_optimal_nutrients, optimal_nutrients\n\n# Apply the function to each row\ndf[['Reduce', 'Increase', 'Opt_N']] = df.apply(recommend_nutrient_action_individual, axis=1).apply(pd.Series)\n\n# Display the DataFrame\nprint(df)\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T16:30:52.968097Z","iopub.execute_input":"2023-11-18T16:30:52.968497Z","iopub.status.idle":"2023-11-18T16:30:53.599093Z","shell.execute_reply.started":"2023-11-18T16:30:52.968465Z","shell.execute_reply":"2023-11-18T16:30:53.597892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Define recommended actions based on rules (example rules)\ndef recommend_nutrient_action_individual(row):\n    optimal_ratio = {'N': 4, 'P': 2, 'K': 1}\n    \n    # Calculate the ratio for each nutrient individually\n    ratios = {nutrient: row[nutrient] / (row['N'] + row['P'] + row['K']) for nutrient in optimal_ratio.keys()}\n\n    # Initialize lists to store nutrient names\n    exceeding_nutrients = []\n    below_optimal_nutrients = []\n    optimal_nutrients = []\n\n    # Check if any nutrient exceeds, falls below, or is within the optimal ratio\n    for nutrient, ratio in ratios.items():\n        if ratio > optimal_ratio[nutrient] / sum(optimal_ratio.values()):\n            exceeding_nutrients.append(nutrient)\n        elif ratio < optimal_ratio[nutrient] / sum(optimal_ratio.values()):\n            below_optimal_nutrients.append(nutrient)\n        else:\n            optimal_nutrients.append(nutrient)\n\n    return exceeding_nutrients, below_optimal_nutrients\n\n# Define recommended actions for water supply based on rainfall and crop-specific optimal conditions\ndef recommend_water_action(row):\n    crop = row['label']\n    rainfall = row['rainfall']\n\n    # Crop-specific optimal conditions\n    optimal_conditions = {\n        'rice': (200, 250),\n        'coffee': (140, 200),\n        'maize': (65, 105),\n        'chickpea': (70, 90),\n        'kidneybeans': (90, 140),\n        'apple': (90, 140),\n        'orange': (90, 140),\n        'pigeonpeas': (100, 200),\n        'mothbeans': (30, 70),\n        'mungbeans': (30, 70),\n        'lentil': (30, 70),\n        'watermelon': (30, 70),\n        'blackgram': (60, 80),\n        'grapes': (60, 80),\n        'pomegranate': (90, 120),\n        'banana': (90, 120),\n        'mango': (90, 120),\n        'muskmelon': (20, 35),\n        'papaya': (150, 250),\n        'coconut':(145,225),\n        'cotton':(65,90),\n        'jute':(150,200)\n    }\n\n    # Get optimal conditions for the crop\n    optimal_range = optimal_conditions.get(crop)\n\n    if optimal_range:\n        # Check if the rainfall is within the optimal range\n        if optimal_range[0] < rainfall < optimal_range[1]:\n            return 'Optimal'\n        elif rainfall <= optimal_range[0]:\n            return 'Increase'\n        else:\n            return 'Reduce'\n    else:\n        return 'No Recommendation'  # Handle cases where the crop is not in the defined list\n\ndef pH_action(row):\n    pH = row['ph']  # Assuming the pH column in your DataFrame is named 'pH'\n\n    # Define pH preferences for different crops\n    crop_preferences = {\n        (6.5, 7.0): ['apple','banana','pomogrante','muskmelon', 'peas', 'beans', 'lentil', 'coconut'],\n        (6.5, 7.5): ['rice'],\n        (4.9, 6.5): ['coffee'],\n        (5.8, 6.0): ['maize'],\n        (6.5, 7.8): ['black Gram'],\n        (5.8, 6.5): ['cotton'],\n        (5.0, 7.4): ['jute'],\n        # Add more pH ranges and corresponding crops as needed\n    }\n\n    # Check if the crop is in the preferences dictionary\n    for pH_range, crops in crop_preferences.items():\n        if row['label'] in crops:\n            lower_limit, upper_limit = pH_range\n\n            # Compare the pH with the preferred range and recommend an action\n            if pH < lower_limit:\n                return 'Increase'\n            elif lower_limit <= pH <= upper_limit:\n                return 'Optimal pH'\n            else:\n                return 'Reduce'\n\n    return 'No Recommendation'  # Handle cases where the crop is not in the preferences dictionary\n\n# Apply the function to each row\ndf[['Reduce_Nutrient', 'Increase_Nutrient']] = df.apply(recommend_nutrient_action_individual, axis=1).apply(pd.Series)\ndf['Water_Action'] = df.apply(recommend_water_action, axis=1)\ndf['pH_Action'] = df.apply(pH_action, axis=1)\n# Display the DataFrame\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:14:01.746057Z","iopub.execute_input":"2023-11-18T18:14:01.746377Z","iopub.status.idle":"2023-11-18T18:14:02.204209Z","shell.execute_reply.started":"2023-11-18T18:14:01.746351Z","shell.execute_reply":"2023-11-18T18:14:02.203214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Sample data\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Define recommended actions based on rules (example rules)\ndef recommend_nutrient_action_individual(row):\n    optimal_ratio = {'N': 4, 'P': 2, 'K': 1}\n    \n    # Calculate the ratio for each nutrient individually\n    ratios = {nutrient: row[nutrient] / (row['N'] + row['P'] + row['K']) for nutrient in optimal_ratio.keys()}\n\n    # Initialize lists to store nutrient names\n    exceeding_nutrients = []\n    below_optimal_nutrients = []\n    optimal_nutrients = []\n\n    # Check if any nutrient exceeds, falls below, or is within the optimal ratio\n    for nutrient, ratio in ratios.items():\n        if ratio > optimal_ratio[nutrient] / sum(optimal_ratio.values()):\n            exceeding_nutrients.append(nutrient)\n        elif ratio < optimal_ratio[nutrient] / sum(optimal_ratio.values()):\n            below_optimal_nutrients.append(nutrient)\n        else:\n            optimal_nutrients.append(nutrient)\n\n    return exceeding_nutrients, below_optimal_nutrients\n# Apply the function to each row\ndf[['Reduce', 'Increase']] = df.apply(recommend_nutrient_action_individual, axis=1).apply(pd.Series)\n\n# Combine the 'Reduce', 'Increase', 'Opt_N' columns into a new column 'Action'\ndf['Action'] = df[['Reduce', 'Increase']].apply(lambda x: ''.join(map(str, x)), axis=1)\n\n# Encode the target column\nlabel_encoder = LabelEncoder()\ndf['Recommended_Action_Encoded'] = label_encoder.fit_transform(df['Action'])\n\n# Drop the intermediate columns if needed\ndf = df.drop(['Reduce', 'Increase', 'Action'], axis=1)\n\n# Define features (X) and target (y)\nX = df[['N', 'P', 'K', 'temperature', 'humidity', 'rainfall']]\ny = df['Recommended_Action_Encoded']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train an SVM Classifier\nsvm_clf = SVC(kernel='linear')\nsvm_clf.fit(X_train, y_train)\n\n# Predict recommended actions for the test set\ny_pred_svm = svm_clf.predict(X_test)\n\n# Decode the predictions back to action labels\ny_pred_labels_svm = label_encoder.inverse_transform(y_pred_svm)\n\n# Assuming y_true and y_pred are your true and predicted labels\nreport = classification_report(y_test, y_pred_svm, zero_division=1)\n\n\n# Print the SVM classification report\nprint(\"SVM Classification Report:\")\nprint(report)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:59:45.621960Z","iopub.execute_input":"2023-11-19T07:59:45.622240Z","iopub.status.idle":"2023-11-19T07:59:46.421055Z","shell.execute_reply.started":"2023-11-19T07:59:45.622217Z","shell.execute_reply":"2023-11-19T07:59:46.419889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\n\n# Load your dataset\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n\n# Encode the target column\nlabel_encoder = LabelEncoder()\ndf['Recommended_Action_Encoded'] = label_encoder.fit_transform(df['label'])\n\n\n\n\n# Define features (X) and target (y)\nX = df[['N', 'P', 'K', 'temperature', 'humidity']]\ny = df['Recommended_Action_Encoded']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_combined = pd.concat([X_train, X_test])\ny_combined = pd.concat([y_train, y_test])\n\n# Fit the label encoder\nlabel_encoder.fit(y_combined)\n\n# Transform y_test\ny_test_encoded = label_encoder.transform(y_test)\n# Define the model\nclf = RandomForestClassifier()\n\n# Define hyperparameters to tune\nparam_dist = {\n    'n_estimators': [50, 100, 150],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Perform randomized search\nrandomized_search = RandomizedSearchCV(estimator=clf, param_distributions=param_dist, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1)\nrandomized_search.fit(X_train, y_train)\n\n# Get the best parameters\nbest_params = randomized_search.best_params_\nprint(\"Best Hyperparameters:\", best_params)\n\n# Train a model with the best hyperparameters\nbest_clf = RandomForestClassifier(**best_params)\nbest_clf.fit(X_train, y_train)\n\n# Predict recommended actions\ny_pred = best_clf.predict(X_test)\n\n# Decode the predictions back to action labels\ny_pred_labels = label_encoder.inverse_transform(y_pred)\n# Print the classification report\n# Convert y_test to numeric labels using the label encoder\ny_test_encoded = label_encoder.transform(y_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\n\n# Print the accuracy\nprint(\"RFC Accuracy:\", accuracy)\n# Print the classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_test_encoded, y_pred_labels,zero_division=1))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T04:06:28.048439Z","iopub.execute_input":"2023-11-24T04:06:28.048942Z","iopub.status.idle":"2023-11-24T04:06:32.796196Z","shell.execute_reply.started":"2023-11-24T04:06:28.048904Z","shell.execute_reply":"2023-11-24T04:06:32.794886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Sample data\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Define features (X) and target (y)\nX = df[['N', 'P', 'K', 'temperature','rainfall']]\ny = df['label']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\n# Create a Random Forest Classifier\nrfc = RandomForestClassifier()\n\n# Train the RFC\nrfc.fit(X_train, y_train)\n\n# Predict recommended actions for the test set\ny_pred_rfc = rfc.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred_rfc)\n\n# Print the accuracy\nprint(\"RFC Accuracy:\", accuracy)\n\n# Print the RFC classification report\nreport = classification_report(y_test, y_pred_rfc, zero_division=1)\nprint(\"RFC Classification Report:\")\nprint(report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Sample data\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Define features (X) and target (y)\nX = df[['N', 'P', 'K', 'temperature','rainfall']]\ny = df['label']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n\n# Create a Random Forest Classifier\nrfc = RandomForestClassifier()\n\n# Train the RFC\nrfc.fit(X_train, y_train)\n\n# Predict recommended actions for the test set\ny_pred_rfc = rfc.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred_rfc)\n\n# Print the accuracy\nprint(\"RFC Accuracy:\", accuracy)\n\n# Print the RFC classification report\nreport = classification_report(y_test, y_pred_rfc, zero_division=1)\nprint(\"RFC Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T04:48:15.917137Z","iopub.execute_input":"2023-11-24T04:48:15.918296Z","iopub.status.idle":"2023-11-24T04:48:16.372457Z","shell.execute_reply.started":"2023-11-24T04:48:15.918259Z","shell.execute_reply":"2023-11-24T04:48:16.371217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Sample data\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Define features (X) and target (y)\nX = df[['N', 'P', 'K', 'temperature', 'humidity']]\ny = df['label']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Encode the target variable\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n# Train a KNN Classifier\nknn_clf = KNeighborsClassifier()\nknn_clf.fit(X_train, y_train_encoded)\n\n# Predict recommended actions for the test set\ny_pred_knn = knn_clf.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test_encoded, y_pred_knn)\n\n# Print the accuracy\nprint(\"KNN Accuracy:\", accuracy)\n\n# Print the KNN classification report\nreport = classification_report(y_test_encoded, y_pred_knn, zero_division=1)\nprint(\"KNN Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T04:55:40.085412Z","iopub.execute_input":"2023-11-24T04:55:40.086463Z","iopub.status.idle":"2023-11-24T04:55:40.161915Z","shell.execute_reply.started":"2023-11-24T04:55:40.086421Z","shell.execute_reply":"2023-11-24T04:55:40.160693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Sample data\ndata = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Define features (X) and target (y)\nX = df[['N', 'P', 'K', 'temperature', 'humidity','rainfall']]\ny = df['label']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Encode the target variable\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n\n# Define hyperparameters to tune\nparam_dist = {\n    'n_neighbors': range(1,9),  # Number of neighbors to consider\n    'weights': ['uniform', 'distance'],  # Weight function used in prediction\n    'p': [1, 2],  # Power parameter for the Minkowski metric\n}\n\n# Perform randomized search for hyperparameter tuning\nrandomized_search = RandomizedSearchCV(estimator=knn_clf, param_distributions=param_dist, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1)\nrandomized_search.fit(X_train, y_train_encoded)\n\n# Get the best parameters\nbest_params = randomized_search.best_params_\nprint(\"Best Hyperparameters:\", best_params)\n# Calculate accuracy\naccuracy = accuracy_score(y_test_encoded, y_pred_knn)\n# Print the accuracy\nprint(\"KNN Accuracy:\", accuracy)\n\n# Print the KNN classification report\nreport = classification_report(y_test_encoded, y_pred_knn, zero_division=1)\nprint(\"KNN Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T04:54:28.248706Z","iopub.execute_input":"2023-11-24T04:54:28.249911Z","iopub.status.idle":"2023-11-24T04:54:28.683048Z","shell.execute_reply.started":"2023-11-24T04:54:28.249859Z","shell.execute_reply":"2023-11-24T04:54:28.681937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}